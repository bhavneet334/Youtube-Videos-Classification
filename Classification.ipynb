{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Video_id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i9E_Blai8vk</td>\n",
       "      <td>TRAVEL VLOG âˆ™ Welcome to Bali | PRISCILLA LEE</td>\n",
       "      <td>I had the chance to fly out to Bali with my wh...</td>\n",
       "      <td>Travel Blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>e2NQE41J5eM</td>\n",
       "      <td>How do I travel so much ! How do I earn money!!</td>\n",
       "      <td>SUBSCRIBE - https://goo.gl/dEtSMJ (â€˜MountainTr...</td>\n",
       "      <td>Travel Blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ehmsJLZlCZ0</td>\n",
       "      <td>Ep 1| Travelling through North East India | Of...</td>\n",
       "      <td>The journey to Arunachal, North East India beg...</td>\n",
       "      <td>Travel Blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-LzdIILq5vE</td>\n",
       "      <td>GOA TRAVEL DIARY | FOUR DAYS IN GOA | TRAVEL O...</td>\n",
       "      <td>Hope you enjoy MY GOA TRAVEL DIARY this video!...</td>\n",
       "      <td>Travel Blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7ByoBJYXU0k</td>\n",
       "      <td>5 Steps to Becoming a Travel Blogger</td>\n",
       "      <td>Travel blogger, Nikki Vargas, of The Pin the M...</td>\n",
       "      <td>Travel Blogs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     Video_id                                              Title  \\\n",
       "0           0  i9E_Blai8vk      TRAVEL VLOG âˆ™ Welcome to Bali | PRISCILLA LEE   \n",
       "1           1  e2NQE41J5eM    How do I travel so much ! How do I earn money!!   \n",
       "2           2  ehmsJLZlCZ0  Ep 1| Travelling through North East India | Of...   \n",
       "3           3  -LzdIILq5vE  GOA TRAVEL DIARY | FOUR DAYS IN GOA | TRAVEL O...   \n",
       "4           4  7ByoBJYXU0k               5 Steps to Becoming a Travel Blogger   \n",
       "\n",
       "                                         Description      Category  \n",
       "0  I had the chance to fly out to Bali with my wh...  Travel Blogs  \n",
       "1  SUBSCRIBE - https://goo.gl/dEtSMJ (â€˜MountainTr...  Travel Blogs  \n",
       "2  The journey to Arunachal, North East India beg...  Travel Blogs  \n",
       "3  Hope you enjoy MY GOA TRAVEL DIARY this video!...  Travel Blogs  \n",
       "4  Travel blogger, Nikki Vargas, of The Pin the M...  Travel Blogs  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"./Dataset_youtube.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2739</td>\n",
       "      <td>the Israel of God Black History Promo 2018 (ex...</td>\n",
       "      <td>the Israel of God Black History Promo 2018 (ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1421</td>\n",
       "      <td>Top 15 Forever Foods for Survival</td>\n",
       "      <td>Top 15 Forever Foods for SurvivalBe a Team Soo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1412</td>\n",
       "      <td>JAPAN Street Food $100 CHALLENGE in Asakusa, T...</td>\n",
       "      <td>ðŸŽ¥MOUNTAIN LAMB IN UZBEKISTAN Â» https://youtu.b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3248</td>\n",
       "      <td>Sacred Rites in Flagstaff, AZ - sacred art, mu...</td>\n",
       "      <td>Established in 1992 we sell Sacred Art and Mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1579</td>\n",
       "      <td>Fast Food Lasagna - Epic Meal Time</td>\n",
       "      <td>MAKE A MEAL WITH US &amp; ARNOLD!!!! http://omaze....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  \\\n",
       "2739  the Israel of God Black History Promo 2018 (ex...   \n",
       "1421                  Top 15 Forever Foods for Survival   \n",
       "1412  JAPAN Street Food $100 CHALLENGE in Asakusa, T...   \n",
       "3248  Sacred Rites in Flagstaff, AZ - sacred art, mu...   \n",
       "1579                 Fast Food Lasagna - Epic Meal Time   \n",
       "\n",
       "                                            Description  \n",
       "2739  the Israel of God Black History Promo 2018 (ex...  \n",
       "1421  Top 15 Forever Foods for SurvivalBe a Team Soo...  \n",
       "1412  ðŸŽ¥MOUNTAIN LAMB IN UZBEKISTAN Â» https://youtu.b...  \n",
       "3248  Established in 1992 we sell Sacred Art and Mus...  \n",
       "1579  MAKE A MEAL WITH US & ARNOLD!!!! http://omaze....  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data,test_data,train_labels,test_labels=train_test_split(data.iloc[:,2:-1],data.iloc[:,-1],test_size=0.2,random_state=1)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bhavneetmanocha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/bhavneetmanocha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/bhavneetmanocha/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/bhavneetmanocha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(data):\n",
    "    for i in range(data.shape[0]):\n",
    "        data.iloc[i,0]=preprocessing.preprocess(data.iloc[i,0])\n",
    "        data.iloc[i,1]=preprocessing.preprocess(data.iloc[i,0])\n",
    "        if i%100==0:\n",
    "            print(i,end=\" \")\n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 "
     ]
    }
   ],
   "source": [
    "preprocessing.vocab={}\n",
    "train_data_x=preprocess_dataset(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5556"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary=preprocessing.vocab\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=sorted(vocabulary,key=lambda x: vocabulary[x],reverse=True)[:100] #atleast occured 10 times\n",
    "features={features[i]:i for i in range(len(features))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data,features):\n",
    "    dataset=[]\n",
    "    for i in range(data.shape[0]):\n",
    "        feat=np.zeros(len(features))\n",
    "        for word in (data.iloc[i,0]+\" \"+data.iloc[i,1]).split():\n",
    "            if word in features.keys():\n",
    "                feat[features[word]]+=1\n",
    "        dataset.append(feat)\n",
    "        if i%100==0:\n",
    "            print(i,end=\" \")\n",
    "    return np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 "
     ]
    }
   ],
   "source": [
    "train_data_x=create_dataset(train_data_x.iloc[:,:],features=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb=MultinomialNB()\n",
    "\n",
    "mnb.fit(train_data_x,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 200 300 400 500 600 700 0 100 200 300 400 500 600 700 "
     ]
    }
   ],
   "source": [
    "test_data_x=preprocess_dataset(test_data)\n",
    "test_data_x=create_dataset(test_data_x.iloc[:,:],features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "         Art and Music       0.90      0.99      0.94       127\n",
      "                  Food       0.97      0.98      0.97        94\n",
      "               History       0.95      0.95      0.95        87\n",
      "         Manufacturing       1.00      0.96      0.98       134\n",
      "Science and Technology       0.98      0.97      0.97       124\n",
      "          Travel Blogs       1.00      0.95      0.97       135\n",
      "\n",
      "              accuracy                           0.97       701\n",
      "             macro avg       0.97      0.97      0.97       701\n",
      "          weighted avg       0.97      0.97      0.97       701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred=mnb.predict(test_data_x)\n",
    "\n",
    "print(classification_report(test_labels,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
